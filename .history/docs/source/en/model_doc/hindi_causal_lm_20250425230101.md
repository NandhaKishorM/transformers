# HindiCausalLM

## Overview

The HindiCausalLM model is a transformer-based causal language model developed by [ConvAI Innovations](https://huggingface.co/convaiinnovations), specifically designed for Hindi language understanding and generation tasks.

This implementation utilizes a standard transformer architecture but has been adapted to match the specific structure and configuration used during the training of the `convaiinnovations/hindi-foundational-model-base` checkpoint. Notably, it uses standard learned positional embeddings and Post-Layer Normalization with a GELU activation in the feed-forward networks.

**Note:** While the configuration allows specifying different activation functions, normalization layers, or positional encodings, the actual modeling code (adapted to load the original weights) currently implements a fixed structure (GELU, LayerNorm, Absolute/Learned Positional Embeddings). The configuration options are primarily for informational purposes or potential future fine-tuning with architectural changes.

## HindiCausalLMConfig

[[autodoc]] transformers.HindiCausalLMConfig

## HindiCausalLMTokenizer

This tokenizer is based on SentencePiece. It handles the tokenization and encoding/decoding specific to the Hindi language model.

[[autodoc]] transformers.HindiCausalLMTokenizer
    - build_inputs_with_special_tokens
    - get_special_tokens_mask
    - create_token_type_ids_from_sequences
    - save_vocabulary

## HindiCausalLMHeadModel

This is the main model class for Hindi Causal LM, including the language modeling head. It directly contains the embedding layers and transformer blocks, mirroring the structure used during original training.

[[autodoc]] transformers.HindiCausalLMHeadModel
    - forward